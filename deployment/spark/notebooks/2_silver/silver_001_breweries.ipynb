{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "650549f1-9c43-4c5d-9b5e-a70c79fed935",
   "metadata": {},
   "source": [
    "## Imports e Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ce0e98-e045-4684-8cc1-aa6e77407fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import current_timestamp, col\n",
    "from pyspark.sql.functions import lower, regexp_replace\n",
    "\n",
    "# Display fix for notebooks\n",
    "# from IPython.core.display import HTML\n",
    "# display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))\n",
    "\n",
    "# Create Spark session with MinIO (S3A)\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Read from MinIO S3A and Write Partitioned\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.3.4\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.endpoint\", \"http://minio:9000\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", \"ROOTUSER\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", \"CHANGEME123\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.path.style.access\", \"true\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .config(\"spark.ui.showConsoleProgress\", \"true\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6dc02f-8d4c-41d9-b567-2e70820a06b7",
   "metadata": {},
   "source": [
    "## Lendo da camada /bronze/ e jogando na /silver/ em parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a733353a-135b-47d0-b381-2c03c6c32a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.json(\"s3a://datalake/1_bronze/001_breweries/breweries.json\")\n",
    "\n",
    "df_cleaned = df.select([\n",
    "    col(c).alias(c.lower().replace(\" \", \"_\")) for c in df.columns\n",
    "])\n",
    "\n",
    "# adicionando timestamp da ingest√£o!\n",
    "df_with_ts = df_cleaned.withColumn(\"ingestion_timestamp\", current_timestamp())\n",
    "\n",
    "# escrevendo particionado por estado\n",
    "df_with_ts.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .partitionBy(\"state\") \\\n",
    "    .parquet(\"s3a://datalake/2_silver/001_breweries/breweries/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
