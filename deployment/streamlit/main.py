import streamlit as st
import pandas as pd
import duckdb
import sqlparse
import s3fs
import pyarrow.parquet as pq
from openai import OpenAI

# T√≠tulo e subt√≠tulo
st.title("Ourinho da ABInBev ü§ñüç∫")
st.markdown(
    "<p style='font-size:18px; color:gray;'>O mascote oficial da camada gold. Fa√ßo queries usando linguagem natural :)</p>",
    unsafe_allow_html=True
)

# Configurar cliente OpenAI
client = OpenAI(api_key="")

# Nome da tabela que ser√° usada no DuckDB
tabela_nome = "breweries_by_type_location"

import pyarrow.dataset as ds
import pyarrow.parquet as pq
import pyarrow.fs

# Cria um filesystem para o MinIO usando pyarrow
minio_fs = pyarrow.fs.S3FileSystem(
    access_key='ROOTUSER',
    secret_key='CHANGEME123',
    endpoint_override='http://localhost:9000',
    region='us-east-1'
)

# Define o path do dataset
parquet_path = "datalake/3_gold/001_breweries/breweries_by_type_location"

# L√™ o diret√≥rio Parquet inteiro como um dataset
dataset = ds.dataset(parquet_path, filesystem=minio_fs, format="parquet")

# Converte para pandas
df = dataset.to_table().to_pandas()

print(df)

# Extrai metadados da tabela
metadata = "\n".join([f"{col}: {dtype}" for col, dtype in zip(df.columns, df.dtypes)])

# Inicializar vari√°veis de sess√£o
if "openai_model" not in st.session_state:
    st.session_state["openai_model"] = "gpt-4"
if "messages" not in st.session_state:
    st.session_state.messages = []

# Mostrar hist√≥rico do chat
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if message["role"] == "assistant":
            if "query" in message:
                st.code(message["query"], language='sql')
            if "dataframe" in message:
                st.write("üìä Resultado da query:")
                st.dataframe(pd.DataFrame(message["dataframe"]))
            if "explanation" in message:
                st.write("üß† Explica√ß√£o do resultado:")
                st.write(message["explanation"])

# Input do usu√°rio
if prompt := st.chat_input("Me pergunte sobre dados na camada gold!"):
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        system_prompt = f"""
        Voc√™ √© um assistente de dados com acesso √† seguinte tabela chamada '{tabela_nome}'.

        Metadados da tabela:
        {metadata}

        Gere uma query SQL compat√≠vel com DuckDB que pode ser executada sobre esse dataframe.
        Se for poss√≠vel gerar a query, retorne SOMENTE ELA.
        Se n√£o for poss√≠vel responder com os dados dispon√≠veis, retorne "FALSE".
        SEMPRE LIMITE A CONSULTA EM 100 LINHAS.
        """

        messages = [{"role": "system", "content": system_prompt}]
        messages += [{"role": m["role"], "content": m["content"]} for m in st.session_state.messages]

        response = client.chat.completions.create(
            model=st.session_state["openai_model"],
            messages=messages,
            stream=False,
        )

        ai_reply = response.choices[0].message.content.strip()

        # Verificar se √© uma query SQL
        if ai_reply != "FALSE" and ai_reply.lower().startswith("select"):
            try:
                con = duckdb.connect()
                con.register(tabela_nome, df)

                result_df = con.execute(ai_reply).fetchdf()
                formatted_query = sqlparse.format(ai_reply, reindent=True, keyword_case='upper')

                explanation_prompt = f"""
                O hist√≥rico do chat at√© agora foi: {st.session_state.messages}.
                A seguinte query foi executada sobre a tabela `{tabela_nome}`:
                {formatted_query}
                O resultado da query foi:
                {result_df.to_markdown(index=False)}
                Resuma o resultado obtido em uma frase."""

                explanation_response = client.chat.completions.create(
                    model=st.session_state["openai_model"],
                    messages=[
                        {"role": "system", "content": "Voc√™ explica resultados de consultas SQL de forma simples."},
                        {"role": "user", "content": explanation_prompt}
                    ]
                )
                explanation = explanation_response.choices[0].message.content

                # Mostrar na tela
                st.code(formatted_query, language='sql')
                st.write("üìä Resultado da query:")
                st.dataframe(result_df)
                st.write("üß† Explica√ß√£o do resultado:")
                st.write(explanation)

                # Salvar tudo na sess√£o
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": ai_reply,
                    "query": formatted_query,
                    "dataframe": result_df.to_dict(),  # Serializado
                    "explanation": explanation
                })

            except Exception as e:
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": f"Erro ao rodar a query: {e}"
                })
                st.error(f"Erro ao rodar a query: {e}")

        else:
            st.session_state.messages.append({
                "role": "assistant",
                "content": "Nenhuma query detectada."
            })
            st.info("""
                    N√£o foi poss√≠vel fazer consulta. 
                    Lembre-se de apenas dou respostas caso consiga gerar 
                    uma query nos dados com base na sua pergunta! """)
