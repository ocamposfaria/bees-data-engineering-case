import streamlit as st
import pandas as pd
import duckdb
import sqlparse
import json
from openai import OpenAI
import pyarrow.dataset as ds
import pyarrow.fs

# T√≠tulo e subt√≠tulo
st.title("Ourinho da ABInBev ü§ñüç∫")
st.markdown(
    "<p style='font-size:18px; color:gray;'>O mascote oficial da camada gold. Fa√ßo queries usando linguagem natural :)</p>",
    unsafe_allow_html=True
)

# Configurar cliente OpenAI (ideal passar a chave via secrets ou env var)
client = OpenAI(api_key="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")

# Nome da tabela que ser√° usada no DuckDB
tabela_nome = "breweries_by_type_location"

# L√™ os metadados do arquivo JSON
with open("gold_metadata/gold_001_breweries.json", "r") as f:
    gold_metadata = json.load(f)

# Formata os metadados para exibi√ß√£o no system prompt
metadata = "\n".join([f"{col}: {dtype}" for col, dtype in gold_metadata.items()])

# Inicializar vari√°veis de sess√£o
if "openai_model" not in st.session_state:
    st.session_state["openai_model"] = "gpt-4"
if "messages" not in st.session_state:
    st.session_state.messages = []

# Mostrar hist√≥rico do chat
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        # S√≥ exibe o conte√∫do bruto se n√£o for uma query formatada
        if "query" not in message:
            st.markdown(message["content"])

        if message["role"] == "assistant":
            if "query" in message:
                st.write("üë®‚Äçüíª Query:")
                st.code(sqlparse.format(message["query"], reindent=True, keyword_case='upper'), language='sql')
            if "dataframe" in message:
                st.write("üìä Resultado da query:")
                st.dataframe(pd.DataFrame(message["dataframe"]))
            if "explanation" in message:
                st.write("üß† Explica√ß√£o do resultado:")
                st.write(message["explanation"])
            if message['content'] == "Nenhuma query detectada.":
                info_message = """
                    N√£o foi poss√≠vel fazer consulta. 
                    Lembre-se de que s√≥ dou respostas caso consiga gerar 
                    uma query nos dados com base na sua pergunta! """
                st.write(info_message)

# Input do usu√°rio
if prompt := st.chat_input("Me pergunte sobre dados na camada gold!"):
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        system_prompt = f"""
        Voc√™ √© um assistente de dados com acesso √† seguinte tabela chamada '{tabela_nome}'.

        Metadados da tabela:
        {metadata}

        Gere uma query SQL compat√≠vel com DuckDB que pode ser executada sobre esse dataframe.
        Se for poss√≠vel gerar a query, retorne SOMENTE ELA.
        Se n√£o for poss√≠vel responder com os dados dispon√≠veis, retorne "FALSE".
        SEMPRE LIMITE A CONSULTA EM 100 LINHAS.
        """

        messages = [{"role": "system", "content": system_prompt}]
        messages += [{"role": m["role"], "content": m["content"]} for m in st.session_state.messages]

        response = client.chat.completions.create(
            model=st.session_state["openai_model"],
            messages=messages,
            stream=False,
        )

        ai_reply = response.choices[0].message.content.strip()

        # Verificar se √© uma query SQL
        if ai_reply != "FALSE" and ai_reply.lower().startswith("select"):
            try:
                # Carrega o dataset APENAS quando a query for v√°lida
                minio_fs = pyarrow.fs.S3FileSystem(
                    access_key='ROOTUSER',
                    secret_key='CHANGEME123',
                    endpoint_override='http://minio:9000',
                    region='us-east-1'
                )

                parquet_path = "datalake/3_gold/001_breweries/breweries_by_type_location"
                dataset = ds.dataset(parquet_path, filesystem=minio_fs, format="parquet")
                df = dataset.to_table().to_pandas()

                # Executa a query
                con = duckdb.connect()
                con.register(tabela_nome, df)
                result_df = con.execute(ai_reply).fetchdf()
                formatted_query = sqlparse.format(ai_reply, reindent=True, keyword_case='upper')

                explanation_prompt = f"""
                O hist√≥rico do chat at√© agora foi: {st.session_state.messages}.
                A seguinte query foi executada sobre a tabela `{tabela_nome}`:
                {formatted_query}
                O resultado da query foi:
                {result_df.to_markdown(index=False)}
                Resuma o resultado obtido em uma frase."""

                explanation_response = client.chat.completions.create(
                    model=st.session_state["openai_model"],
                    messages=[
                        {"role": "system", "content": "Voc√™ explica resultados de consultas SQL de forma simples."},
                        {"role": "user", "content": explanation_prompt}
                    ]
                )
                explanation = explanation_response.choices[0].message.content

                # Mostrar na tela
                st.write("üë®‚Äçüíª Query:")
                st.code(formatted_query, language='sql')
                st.write("üìä Resultado da query:")
                st.dataframe(result_df)
                st.write("üß† Explica√ß√£o do resultado:")
                st.write(explanation)

                # Salvar tudo na sess√£o
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": ai_reply,
                    "query": formatted_query,
                    "dataframe": result_df.to_dict(),  # Serializado
                    "explanation": explanation
                })

            except Exception as e:
                # Mostrar erro corretamente
                error_message = f"Erro ao rodar a query: {e}"
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": error_message
                })
                st.error(error_message)

        else:
            # Mostrar .info corretamente no hist√≥rico
            info_message = """
                N√£o foi poss√≠vel fazer consulta. 
                Lembre-se de que s√≥ dou respostas caso consiga gerar 
                uma query nos dados com base na sua pergunta! """
            st.session_state.messages.append({
                "role": "assistant",
                "content": info_message
            })
            st.write(info_message)

# para debug
# print(st.session_state.messages)